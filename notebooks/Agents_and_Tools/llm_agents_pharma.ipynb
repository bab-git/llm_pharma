{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents for Clinical Trial Management\n",
    "\n",
    "In this notebook, we develop an agent-based Large Language Model (LLM) application to automate the evaluation of patients for potential clinical trials. By leveraging documents related to patients' medical histories, clinical policies, and trial inclusion criteria, such an agentic system can significantly enhance the quality of evaluations and reduce the time required.\n",
    "\n",
    "We use limited demo databases and simple agentic tools and pipelines to demonstrate the capabilities of such LLM systems. For real-world applications, more comprehensive medical databases, in collaboration with clinical specialists, will be necessary. Additionally, more advanced tools (e.g., advanced Retrieval-Augmented Generation (RAG) methods) must be incorporated for real applications.\n",
    "\n",
    "**Objective:** Automate clinical trial data management, analysis, compliance checks, and reporting.\n",
    "\n",
    "## Key Components of This Design: \n",
    "1. Patient Data Collection: Gather comprehensive medical histories and relevant patient information.\n",
    "2. Patient Data Analysis: Analyze patient data to identify key health indicators and relevant medical conditions.\n",
    "3. Clinical Compliance Verification: Ensure patient data complies with clinical policies and trial eligibility criteria.\n",
    "4. Trial Matching: Match patients with suitable clinical trials based on their medical profiles.\n",
    "5. Human-in-the-Loop Interventions: Allow clinical experts to review and modify intermediate and final outcomes.\n",
    "\n",
    "## Technologies and Tools Used:\n",
    "- Local Models: Embedding of policies and trial information.\n",
    "- Local Vector Stores: Information retrieval using metadata.\n",
    "- Information Retrieval: Using metadata to find relevant documents.\n",
    "- Chains of LLM Calls: Sequential LLM calls to perform complex tasks.\n",
    "- Python Shell: LLM integration for performing numerical calculations.\n",
    "- Agentic Graph: Deploying a workflow for evaluating patients and trials.\n",
    "- Human-in-the-Loop: Clinical experts can intervene and modify the evaluation process and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "# Loading the requied environment variables\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Clinical Trial Management\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "policy_vstore_created = False\n",
    "trials_vstore_created = False\n",
    "trials_db_downloaded = False\n",
    "chromadb_path = \"../../chroma_db\"\n",
    "policy_collection = \"policy-chroma\"\n",
    "trial_collection = \"trial-chroma\"\n",
    "\n",
    "modelID = \"gpt-3.5-turbo\"\n",
    "n_retrieved_policies = 1 # Number of most relevant policies to retrieve per patient\n",
    "# n_retries = 6\n",
    "n_retrieved_trials = 6\n",
    "\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature = 0.0, model=modelID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pprint\n",
    "# A function for printing nicely\n",
    "def nprint(text, indent=2):\n",
    "    pp = pprint.PrettyPrinter(indent=indent)\n",
    "    pp.pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the demo datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patients database\n",
    "\n",
    "We create a sample dataset of patients with their medical history, previous trials, and other relevant information.   \n",
    "We use random names, diseases, and past or ongoing trials.  \n",
    "This is a demo dataset limited information. However, for real cases, a more complit medical history of patients will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Generate the sample data again for display\n",
    "columns = [\"patient_id\", \"name\", \"age\", \"medical_history\", \"previous_trials\", \"trial_status\", \"trial_completion_date\"]\n",
    "data = []\n",
    "\n",
    "# Given names and surnames\n",
    "names = [\"John\", \"Jane\", \"Alice\", \"Michael\", \"Emily\", \"Daniel\", \"Sophia\", \"James\", \"Emma\", \"Oliver\"]\n",
    "surnames = [\"Doe\", \"Smith\", \"Johnson\", \"Brown\", \"Davis\", \"Garcia\", \"Martinez\", \"Anderson\", \"Thomas\", \"Wilson\"]\n",
    "\n",
    "# Generate all possible unique combinations of names and surnames\n",
    "combinations = [(name, surname) for name in names for surname in surnames]\n",
    "\n",
    "# Shuffle the combinations to ensure randomness\n",
    "random.shuffle(combinations)\n",
    "\n",
    "# Select the first 100 unique combinations\n",
    "unique_names = combinations[:100]\n",
    "\n",
    "# Generate the full names\n",
    "full_names = [f\"{name} {surname}\" for name, surname in unique_names]\n",
    "\n",
    "with open('../../source_data/diseases_list.json', 'r') as file:\n",
    "        trial_diseases =  json.load(file)\n",
    "\n",
    "list_trial_diseases = list({disease for diseases in trial_diseases.values() for disease in diseases})\n",
    "\n",
    "other_medical_conditions = [\"Hypertension\", \"Diabetes\", \"Asthma\", \"Heart Disease\", \"Arthritis\",\n",
    "                      \"Chronic Pain\", \"Anxiety\", \"Depression\", \"Obesity\"]\n",
    "\n",
    "all_conditions = list(set(list_trial_diseases + other_medical_conditions))\n",
    "\n",
    "trial_statuses = [\"Completed\", \"Ongoing\", \"Withdrawn\"]\n",
    "\n",
    "def random_date(start, end):\n",
    "    return start + timedelta(days=random.randint(0, int((end - start).days)))\n",
    "\n",
    "# start_date must be 2 years before now\n",
    "start_date = datetime.now() - timedelta(days=365 * 2)\n",
    "# start_date = datetime(2020, 1, 1)\n",
    "\n",
    "# end_date must be a month before now\n",
    "end_date = datetime.now() - timedelta(days=10)\n",
    "# end_date = datetime(2023, 1, 1)\n",
    "\n",
    "for i in range(1, 101):\n",
    "    name = random.choice(full_names)\n",
    "    age = random.randint(20, 80)\n",
    "    medical_history = random.choice(all_conditions)\n",
    "    \n",
    "    if random.choice([True, False]):\n",
    "        previous_trials = f\"NCT0{random.randint(1000000, 9999999)}\"\n",
    "        trial_status = random.choice(trial_statuses)\n",
    "        trial_completion_date = random_date(start_date, end_date).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        previous_trials = \"\"\n",
    "        trial_status = \"\"\n",
    "        trial_completion_date = \"\"\n",
    "    if trial_status == \"Ongoing\":\n",
    "        trial_completion_date = \"\"\n",
    "\n",
    "    data.append((i, name, age, medical_history, previous_trials, trial_status, trial_completion_date))\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "# save df to csv\n",
    "df.to_csv(\"patients.csv\", index=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a local SQLite database for patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "database_file = 'patients_database.db'\n",
    "df = pd.read_csv('patients.csv')\n",
    "if overwrite or not os.path.exists(database_file):\n",
    "    if os.path.exists(database_file):\n",
    "        os.remove(database_file)\n",
    "    conn = sqlite3.connect(database_file)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS patients (\n",
    "        patient_id INTEGER PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        age INTEGER,\n",
    "        medical_history TEXT,\n",
    "        previous_trials TEXT,\n",
    "        trial_status TEXT,\n",
    "        trial_completion_date TEXT\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    # Insert DataFrame into SQLite table\n",
    "    df.to_sql('patients', conn, if_exists='append', index=False)\n",
    "\n",
    "    # Commit and close the connection\n",
    "    conn.commit()\n",
    "else:\n",
    "    conn = sqlite3.connect(database_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "query = 'SELECT * FROM patients'\n",
    "\n",
    "# Execute the query and fetch all results\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Optionally, you can get the column names\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "\n",
    "# Convert the results to a Pandas DataFrame for better readability\n",
    "df = pd.DataFrame(rows, columns=column_names)\n",
    "print(len(df))\n",
    "\n",
    "# Display the DataFrame\n",
    "conn.close()\n",
    "\n",
    "db = database_file\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical Trials database\n",
    "\n",
    "We download a sample clinical trials database from a [publicly available source]('https://raw.githubusercontent.com/futianfan/clinical-trial-outcome-prediction/main/data/raw_data.csv').   \n",
    "Details are provided in the [helper function](../../src/helper_functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_dir = os.path.abspath('../../src')  # Gets the absolute path to the src directory\n",
    "sys.path.append(module_dir)\n",
    "from helper_functions import dataset_create_trials\n",
    "\n",
    "overwrite = False\n",
    "if trials_db_downloaded and not overwrite:\n",
    "    print(f'Trials database already downloaded and stored in {trials_path}')\n",
    "    df_trials = pd.read_csv(trials_path)\n",
    "else:\n",
    "    df_trials, trials_path = dataset_create_trials(status='recruiting')\n",
    "    trials_db_downloaded = True\n",
    "\n",
    "# print the ctriteria column value froom 4 random rows of the dataferam. use a for loop\n",
    "df_samples = df_trials.sample(4).reset_index(drop=True)\n",
    "for i in range(4):\n",
    "    print(f'---- Sample {i+1} ----')\n",
    "    print(df_samples.iloc[i]['criteria'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vectore Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vstore for policy database\n",
    "\n",
    "To create a vector store for the policy database, we will use perform local embedding via NomicEmbeddings.   \n",
    "Also, to treat each policy separately, we split the policies main document into per policy chunks.   \n",
    "Note that this is a problem specific strategy, and may not be appropriate for all RAG applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "import chromadb\n",
    "\n",
    "# vstore_delete = False\n",
    "vstore_load = True\n",
    "markdown_path = \"../../source_data/instut_trials_policy.md\"\n",
    "\n",
    "with open(markdown_path, \"r\") as f:\n",
    "    policy_text = f.read()\n",
    "\n",
    "\n",
    "doc_splits = [\n",
    "    Document(page_content= txt, metadata={\"source\": markdown_path}) for txt in re.split(r\"(?=\\n###)\", policy_text)\n",
    "    ]\n",
    "\n",
    "# the title of markdown is not required in the split\n",
    "doc_splits = doc_splits[1:]    \n",
    "\n",
    "print(len(doc_splits))\n",
    "doc_splits\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path = chromadb_path)\n",
    "\n",
    "if vstore_load == False:\n",
    "    vectorstore.delete_collection()\n",
    "\n",
    "\n",
    "# if chromadb_path exists\n",
    "if os.path.exists(chromadb_path) and vstore_load:\n",
    "    vectorstore = Chroma(\n",
    "        client=persistent_client,\n",
    "        collection_name=policy_collection,\n",
    "        embedding_function=NomicEmbeddings(model=\"nomic-embed-text-v1.5\",\n",
    "                                inference_mode='local'),\n",
    "    )\n",
    "    print('Vectore store loaded from existing chromadb')\n",
    "    # vectorstore._collection.count()\n",
    "else:\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_splits,\n",
    "        client=persistent_client,\n",
    "        collection_name=policy_collection,\n",
    "        # persist_directory=chromadb_path,\n",
    "        embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\",\n",
    "                                inference_mode='local'),\n",
    "    )\n",
    "    print('Vectore store created and stored in persistent chromadb client')\n",
    "print(vectorstore._collection.count())\n",
    "doc_splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vstore for trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicy, we just work on 3 main categories of cancer, lukemia, and mental health problems.   \n",
    "This selection gives us a managable set of trials as a demo application.   \n",
    "However, for a more proper application, categories can be extended with the help of domain specialists.\n",
    "\n",
    "The vectore store is created using chromadb and as a persistent client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import disease_map\n",
    "\n",
    "vstore_delete = False\n",
    "\n",
    "trial_docs = []\n",
    "for i, row in df_trials.iterrows():\n",
    "    disease = disease_map(row['diseases'])\n",
    "    if disease == 'other_conditions':\n",
    "        continue\n",
    "    doc = Document(\n",
    "        page_content=row['criteria'],\n",
    "        metadata={\n",
    "            \"nctid\": row['nctid'],\n",
    "            \"status\": row['status'],\n",
    "            # \"why_stop\": row['why_stop'],\n",
    "            # \"label\": row['label'],\n",
    "            # \"phase\": row['phase'],\n",
    "            \"diseases\": str(row['diseases']),\n",
    "            \"disease_category\": disease[0],\n",
    "            \"drugs\": row['drugs'],            \n",
    "        }\n",
    "    )\n",
    "    trial_docs.append(doc)\n",
    "# trial_docs\n",
    "\n",
    "print(trial_docs[0].metadata)\n",
    "\n",
    "list_remove = set()\n",
    "for i, doc in enumerate(trial_docs):\n",
    "    if len(doc.page_content)>10000:\n",
    "        list_remove.add(i)\n",
    "        # print(doc.metadata)\n",
    "    if doc.metadata['disease_category'] == 'other_conditions':\n",
    "        list_remove.add(i)\n",
    "        # print(doc.metadata)\n",
    "# remove list_remove indexes from trial_docs\n",
    "trial_docs = [doc for i, doc in enumerate(trial_docs) if i not in list_remove]\n",
    "\n",
    "# print(len(trial_docs[11].page_content))\n",
    "# trial_docs.pop(11)\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path = chromadb_path)\n",
    "\n",
    "if vstore_delete == True:\n",
    "    vectorstore_trials.delete_collection()\n",
    "    trials_vstore_created = False\n",
    "    vstore_delete = False\n",
    "    print(\"vstore deleted\")\n",
    "\n",
    "vectorstore_trials = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=trial_collection,\n",
    "    embedding_function=NomicEmbeddings(model=\"nomic-embed-text-v1.5\",\n",
    "                            inference_mode='local'),\n",
    ")\n",
    "if vectorstore_trials._collection.count() == 0:\n",
    "    vectorstore_trials = Chroma.from_documents(\n",
    "        documents=trial_docs,\n",
    "        client=persistent_client,\n",
    "        collection_name=trial_collection,\n",
    "        # persist_directory=chromadb_path,\n",
    "        embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\",\n",
    "                                inference_mode='local'),\n",
    "    )\n",
    "    trials_vstore_created = True\n",
    "    print(\"Vectorstore is created now\")\n",
    "else:\n",
    "    print(\"Loading the vectorstore from persistent client\")\n",
    "\n",
    "print(vectorstore_trials._collection.count())\n",
    "trial_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools:\n",
    "Here we define some tools that the agent needs to use for evaluation of the patient, general policies, and clinic trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Data Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def get_patient_data(patient_id: int) -> dict:\n",
    "    \"\"\"Fetch all fields for the patient based on the given patient_id as an integer.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the patient's medical history.        \n",
    "    \"\"\"    \n",
    "\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()    \n",
    "    query = 'SELECT * FROM patients WHERE patient_id=?'\n",
    "    cursor.execute(query, (patient_id,))\n",
    "    patient_data = cursor.fetchone()\n",
    "    # rows = cursor.fetchall()\n",
    "    column_names = [column[0] for column in cursor.description]\n",
    "    conn.close()\n",
    "    if patient_data is None:\n",
    "        return None\n",
    "    else:    \n",
    "        results = dict(zip(column_names, patient_data))    \n",
    "    return results\n",
    "\n",
    "# Also possible to add a new patient\n",
    "def add_patient_data(patient_data: dict):    \n",
    "    \"\"\"Adds a new patient to the SQLite database.\"\"\"\n",
    "    \n",
    "    name = patient_data['name']\n",
    "    age = patient_data['age']\n",
    "    medical_history = patient_data['medical_history']\n",
    "    previous_trials = patient_data['previous_trials']\n",
    "    trial_status = patient_data['trial_status']\n",
    "    last_trial_dates = patient_data['last_trial_dates']\n",
    "\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Insert the new patient data into the database\n",
    "    cursor.execute('''\n",
    "    INSERT INTO patients (name, age, medical_history, previous_trials, trial_status, last_trial_dates)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (name, age, medical_history, previous_trials, trial_status, last_trial_dates))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_patient_id = 56\n",
    "patient_data = get_patient_data(sample_patient_id)\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "parser = StrOutputParser()\n",
    "prompt_profile = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are the Clinical Research Coordinator in the screening phase of a clinical trial. \n",
    "    Use the following patient data to write the patient profile for the screening phase.\n",
    "    The patient profile is a summary of the patient's information in continuous text form.    \n",
    "    If they had no previous trial participation, exclude trial status and trial completion date.\\n\n",
    "    Do not ignore any available information.\\n \n",
    "    In a separate section of the profile, also suggest medical trial categories related to patient's disease history.\\n    \n",
    "    Write the patient profile in 3 to 4 short sentences.\\n\\n\n",
    "    {patient_data}\"\"\",\n",
    "    input_variables=[\"patient_data\"],\n",
    ")\n",
    "# model = ChatOpenAI(temperature = 0.0, model=modelID)\n",
    "\n",
    "chain_profile = prompt_profile | model | parser\n",
    "# to preserve the patient's private information\n",
    "\n",
    "if patient_data.get('name'):\n",
    "    del patient_data['patient_id']\n",
    "    del patient_data['name']\n",
    "\n",
    "patient_profile = chain_profile.invoke({'patient_data': patient_data})\n",
    "nprint(patient_profile) # patient_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to preserve the patient's private information\n",
    "if patient_data.get('name'):\n",
    "    del patient_data['patient_id']\n",
    "    del patient_data['name']\n",
    "\n",
    "patient_profile = chain_profile.invoke({'patient_data': patient_data})\n",
    "nprint(patient_profile) # patient_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_policy = vectorstore.as_retriever(search_kwargs={\"k\": n_retrieved_policies})\n",
    "\n",
    "# sample policy retrieval\n",
    "question = \"\\ntrial_completion_date: 2024-04-01\"\n",
    "docs_retrieved = retriever_policy.get_relevant_documents(question)\n",
    "print(len(docs_retrieved))\n",
    "doc_txt = docs_retrieved[0].page_content\n",
    "docs_retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Evaluator with Python REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing import Annotated, List\n",
    "# from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# import functools\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "\n",
    "def policy_repl(policy, patient_profile):\n",
    "\n",
    "    class codesc(BaseModel):\n",
    "        code: str = Field(\n",
    "            description=\"The code to execute. IMPORTANT: the last line of code must always finish with a print(...).\"\n",
    "        )\n",
    "\n",
    "    python_repl = PythonREPL()\n",
    "    python_repl_tool = Tool(\n",
    "        name=\"python_repl\",\n",
    "        description=\"\"\"\n",
    "        A Python shell. Use this to execute python commands. Input should be a valid python command. IMPORTANT: alwyas print the output value out with `print(...)`.\n",
    "\n",
    "        Wrong code example:\n",
    "        ```python\n",
    "        A = 12\n",
    "        B = 20\n",
    "        A_bigger = A > B    \n",
    "        ```\n",
    "\n",
    "        Correct code example:\n",
    "        ```python\n",
    "        A = 12\n",
    "        B = 20\n",
    "        A_bigger = A > B\n",
    "        print(\"A_bigger\")\n",
    "        ```\n",
    "        \"\"\",\n",
    "        func=python_repl.run,\n",
    "        args_schema=codesc,\n",
    "    )        \n",
    "\n",
    "    prompt_repl = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a Principal Investigator (PI) for evaluating patients for clinical trials.\" \n",
    "                \"You are asked to compare the patient profile document to the institution policies document.\"\n",
    "                \"You must determine if the patient is eligible based on the following documnents or not.\"\n",
    "                # \"Use the following institution policy(s) to find if the patient is eligibile for trials.\"\n",
    "                \"\\n #### Here is the patient profile document: \\n {patient_profile}\\n\\n\"\n",
    "                # \"\\n Here is/are the retrieved policy(s) document: \\n {context}\\n\\n\"\n",
    "\n",
    "                \"-------------------\\n\"\n",
    "                \n",
    "                \"Today date is {date}.\\n\\n\"\n",
    "\n",
    "                # \"EXCLUSION terms in the patient profile should be removed from policies.\\n\"                                                \n",
    "                \"Do not use your own knowledege regarding clinical trials. Restrict your judgment Only to the information given in documents.\\n\"\n",
    "                \"You have access to the following tools: {tool_names}.\"\n",
    "                # \"\\n You may generate only safe python code.\"\n",
    "                \"\\n IMPORTANT: Do not use this tool {tool_names} when thre is no numerical or date related information in the policy document.\\n\\n\"\n",
    "                \n",
    "                \"Give a binary 'yes' or 'no' score in the response to indicate whether the patient is eligible according to the given policy ONLY.\"\n",
    "                \"If the patient is not eligible then also include the reason in your response.\", \n",
    "            ),\n",
    "            # MessagesPlaceholder(variable_name=\"examples\"),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),            \n",
    "        ]\n",
    "    )   \n",
    "\n",
    "    tools = [python_repl_tool]\n",
    "    # patient_profile = state[\"patient_profile\"]\n",
    "\n",
    "    date = datetime.today().date()\n",
    "    prompt_repl = prompt_repl.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    prompt_repl = prompt_repl.partial(date=date)    \n",
    "    prompt_repl = prompt_repl.partial(patient_profile=patient_profile)    \n",
    "\n",
    "    agent = create_openai_tools_agent(model, tools, prompt_repl)\n",
    "    agent_with_tool = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "    message = f\"Here is the retrieved policy document: \\n {policy}\\n\\n\"\n",
    "    # nprint(message)    \n",
    "    result = agent_with_tool.invoke({\"messages\": [HumanMessage(content=message)]} )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample policy evaluation\n",
    "policy = docs_retrieved[0].page_content\n",
    "# nprint(policy)\n",
    "policy_repl(policy, patient_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trials Retriever \n",
    "\n",
    "We use SelfQueryRetriever module that also uses metadata information. This retrival can quickly find relevant trials based on metadata such as disease category, drug names, etc.   \n",
    "The value of such retrival becomes important for real applications, where patient profiles contain more comphrehensive medical histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"disease_category\",\n",
    "        description=\"Defines the disease group of patients related to this trial. One of ['cancer', 'leukemia', 'mental_health']\",\n",
    "        # description=\"The trial is for patients when their disease is related to this category. One of ['cancer', 'leukemia', 'mental_health']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"drugs\",\n",
    "        description=\"List of drug names used in the trial\",\n",
    "        type=\"str\",\n",
    "    ),    \n",
    "]\n",
    "\n",
    "document_content_description = \"The list of patient conditions to include or exclude them from the trial\"\n",
    "retriever_trial_sq = SelfQueryRetriever.from_llm(\n",
    "    model,\n",
    "    vectorstore_trials,\n",
    "    # vectorstore_trials_mpnet,\n",
    "    document_content_description,\n",
    "    metadata_field_info\n",
    "    # enable_limit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample trial retrieval\n",
    "question = f\"\"\"\n",
    "Which trials are relevant to the patient with the following medical history?\\n\n",
    "patient_profile: {patient_profile}\n",
    "\"\"\"        \n",
    "docs_retrieved = retriever_trial_sq.get_relevant_documents(question)\n",
    "print(docs_retrieved[0].metadata)\n",
    "print(docs_retrieved[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grade(BaseModel):\n",
    "        \"\"\"The result of the trial's relevance check as relevance score and explanation.\"\"\"\n",
    "\n",
    "        relevance_score: str        \n",
    "        explanation: str = Field(description=\"Reasons to the given relevance score.\")        \n",
    "        further_information: str\n",
    "\n",
    "prompt_grader = PromptTemplate(\n",
    "        template=\"\"\" \n",
    "        You are a Principal Investigator (PI) for evaluating patients for clinical trials.\\n\n",
    "        Your task is to evaluate the relevance of a clinical trial to the given patient's medical profile. \\n\n",
    "        \n",
    "        \n",
    "        The clinical trial is related to these diseases: {trial_diseases} \\n\n",
    "        Here are the inclusion and exclusion criteria of the trial: \\n\\n {document} \\n\\n\n",
    "        \n",
    "        ===============                \n",
    "        Use the following steps to determine relevance and provide the necessary fields in your response: \\n\n",
    "        1- If the patient's profile meets any exclusion criteria, then the trial is not relevant --> relevance_score = 'No'. \\n\n",
    "        2- If the patient has or had the trial's inclusion diseases, then it is relevant --> relevance_score = 'Yes'.\\n        \n",
    "        3- If the patient did not have the trial's inclusion diseases, then it is not relevant --> relevance_score = 'No'.\\n\n",
    "                       \n",
    "        Example 1: \n",
    "The patient has Arthritis and the trial is related to pancreatic cancer. --> relevance_score = 'No' \\n\n",
    "        \n",
    "        Example 2: \n",
    "The patient has pancreatic cancer and the trial is also related to carcinoma pancreatic cancer. --> relevance_score = 'Yes' \\n\n",
    "\n",
    "        Example 3: \n",
    "The patient has pancreatic cancer and the trial is related to breast cancer or ovarian cancer. --> relevance_score = 'No'. \\n \n",
    "\n",
    "        Bring your justification in the explanation. \\n\n",
    "\n",
    "        Mention further information that is needed from the patient's medical history related to the trial's criteria \\n\n",
    "\n",
    "        ===============\n",
    "        Here is the patient's medical profile: {patient_profile} \\n\\n\n",
    "        \"\"\",\n",
    "        input_variables=[\"document\", \"patient_profile\", \"trial_diseases\"],\n",
    "    )\n",
    "\n",
    "llm_with_tool = model.with_structured_output(grade)\n",
    "retrieval_grader = prompt_grader | llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs_retrieved[0]\n",
    "doc_txt = doc.page_content\n",
    "trial_diseases = doc.metadata.get(\"diseases\")\n",
    "trial_score = retrieval_grader.invoke({\"patient_profile\": patient_profile, \"document\": doc_txt, \"trial_diseases\": trial_diseases})\n",
    "\n",
    "for score in trial_score:\n",
    "    nprint(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination Grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score and explanation for whether the LLM's generated answer is grounded in / supported by the facts in the patient's medical profile.\"\"\"\n",
    "    # \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the patient's medical profile, 'yes' or 'no'\"\n",
    "    )\n",
    "    Reason: str = Field(description=\"Reasons to the given relevance score.\")\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm_with_tool = model.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by the facts in the patient's medical profile. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the facts in the patient's medical profile.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Patient's medical profile: \\n\\n {patient_profile} \\n\\n LLM generation: {explanation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm_with_tool\n",
    "print(trial_score.relevance_score)\n",
    "explanation = trial_score.explanation\n",
    "nprint(explanation)\n",
    "# docs = patient_profile\n",
    "score = hallucination_grader.invoke({\"patient_profile\": patient_profile, \"explanation\": explanation})\n",
    "grade = score.binary_score\n",
    "print(grade)\n",
    "nprint(score.Reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile Rewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "A trial cross match resulted in no trials for the patient.\n",
    "As a clinical specialist write a medical profile for this patient and see if their disease(s) can be relevant to any of these categories of mental_health, cancer, or leukemia.\n",
    "If yes, then suggest relevant medical trial categories for the agent.\n",
    "If no, then do not add anything there.\n",
    "\n",
    "Your output must be as below:\n",
    "<a text summart of original profile>\n",
    "Suggested relevant trials:\n",
    "<bullet points of relevant medical trial categoriyes from the above with a one line reason>\n",
    "\n",
    "Only include categories which can be related to patient diseases in more often cases.\n",
    "Disregard categories which ocasionaly or in some cases can be relevant to patient diseases.\n",
    "\n",
    "example:\n",
    "The patient is a X-year-old with a medical history of Y. They have participated ........  previous trials, and their trial status and completion date .........\n",
    "Suggested relevant trials:\n",
    "category X: [patient's disease] can be related to X due to Y.\n",
    "\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is a patient data:\\n\\n {patient_data} \\n write a patient profile.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "profile_rewriter_chain = re_write_prompt | model | StrOutputParser()\n",
    "profile_rewriter_chain.invoke({\"patient_data\": patient_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    last_node: str\n",
    "    patient_prompt: str\n",
    "    patient_id: int\n",
    "    policy_eligible: bool\n",
    "    rejection_reason: str\n",
    "    patient_data: dict\n",
    "    patient_profile: str\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    trial_searches: int\n",
    "    max_trial_searches: int    \n",
    "    policies: List[Document]\n",
    "    checked_policy: Document\n",
    "    unchecked_policies: List[Document]\n",
    "    trials: List[Document]\n",
    "    relevant_trials: list[dict]\n",
    "    ask_expert: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from operator import itemgetter\n",
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "class Patient_ID(BaseModel):\n",
    "    patient_id: int\n",
    "    # no_id: bool\n",
    "\n",
    "def patient_collector_node(state: AgentState):\n",
    "    patient_data_prompt = \"\"\"You are a helpful assistance in extrcting patient's medical history.\n",
    "Based on the following request identify and return the patient's ID number.\n",
    "\"\"\"\n",
    "\n",
    "    response = model.with_structured_output(Patient_ID).invoke([\n",
    "        SystemMessage(content=patient_data_prompt),\n",
    "        HumanMessage(content=state['patient_prompt'])\n",
    "    ])\n",
    "    patient_id = response.patient_id\n",
    "    # print(response)\n",
    "    print(f\"Patient ID: {patient_id}\")\n",
    "    patient_data = get_patient_data(patient_id)\n",
    "    print(patient_data)\n",
    "    if patient_data is not None:        \n",
    "        if patient_data.get('name'):\n",
    "            del patient_data['patient_id']\n",
    "            del patient_data['name']\n",
    "        patient_profile = chain_profile.invoke({'patient_data': patient_data})\n",
    "\n",
    "    return {\n",
    "        \"last_node\": \"patient_collector\",\n",
    "        \"patient_data\": patient_data,\n",
    "        \"patient_profile\": patient_profile,\n",
    "        \"patient_id\": patient_id,\n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1,\n",
    "        'policy_eligible': 'N/A'\n",
    "        }\n",
    "\n",
    "def policy_search(state: AgentState) -> List[Document]:    \n",
    "    question = f\"\"\"\n",
    "    Does the following patient profile comply with the institutional policies?\\n\n",
    "    {patient_profile}\n",
    "    \"\"\"\n",
    "    docs_retrieved = retriever_policy.get_relevant_documents(question)\n",
    "    if docs_retrieved is None:\n",
    "        docs_retrieved = retriever_policy.get_relevant_documents(question)\n",
    "    return {\n",
    "        \"last_node\": \"policy_search\",\n",
    "        \"policies\": docs_retrieved,\n",
    "        \"unchecked_policies\": docs_retrieved.copy(),\n",
    "    }\n",
    "\n",
    "def policy_evaluator(state: AgentState, policy_doc: Document = None):\n",
    "    if policy_doc is None:\n",
    "        policy_doc = state['unchecked_policies'][0]\n",
    "    \n",
    "    policy_header = policy_doc.page_content.split('\\n', 2)[1]\n",
    "    print(f'Evaluating Policy:\\n {policy_header}')\n",
    "    \n",
    "    policy = policy_doc.page_content\n",
    "    \n",
    "    result = policy_repl(policy, state['patient_profile'])\n",
    "    # nprint(result['output'])\n",
    "\n",
    "    class eligibility(BaseModel):\n",
    "        \"\"\" Give the patient's eligibility result.\"\"\"\n",
    "\n",
    "        eligibility: str = Field(description=\"Patient's eligibility for the clinical trial. 'yes' or 'no'\")\n",
    "        reason: str = Field(description=\"The reason(s) only if the patient is not eligible for clinical trials. Othereise use N/A\")\n",
    "\n",
    "        class Config:\n",
    "            schema_extra = {\n",
    "                \"example\": {\n",
    "                    \"eligibility\": 'yes',\n",
    "                    \"reason\": \"N/A\",\n",
    "                },\n",
    "                \"example 2\": {\n",
    "                    \"eligibility\": 'no',\n",
    "                    \"reason\": \"The patient is pregnant at the moment.\",\n",
    "                },                \n",
    "            }\n",
    "\n",
    "    llm_with_tools = model.bind_tools([eligibility])\n",
    "    message = f\"\"\"Evaluation of the patient's eligibility:\n",
    "    {result['output']}\\n\\n\n",
    "    Is the patient eligible according to this policy?\"\"\"\n",
    "    response = llm_with_tools.invoke(message)\n",
    "            \n",
    "    state[\"policy_eligible\"] = response.tool_calls[0]['args']['eligibility'] == 'yes'\n",
    "    state[\"rejection_reason\"] = response.tool_calls[0]['args']['reason']\n",
    "    \n",
    "    # remove the first element of unchecked_policies\n",
    "    state['unchecked_policies'].pop(0)\n",
    "    state[\"revision_number\"] = state.get(\"revision_number\", 1) + 1\n",
    "    state['checked_policy'] = policy_doc\n",
    "    state['last_node'] = 'policy_evaluator'\n",
    "\n",
    "    return state\n",
    "\n",
    "def trial_search(state: AgentState):\n",
    "    \"\"\"\n",
    "    This node searches the trial database to retrieve a list of clinical trials that match the patient's medical history.\n",
    "    \"\"\"\n",
    "\n",
    "    patient_profile = state['patient_profile']\n",
    "\n",
    "    question = f\"\"\"\n",
    "    Which trials are relevant to the patient with the following medical history?\\n\n",
    "    patient_profile: {patient_profile}\n",
    "    \"\"\"        \n",
    "    docs_retrieved = retriever_trial_sq.get_relevant_documents(question)\n",
    "    # print(state)\n",
    "    trial_searches = state.get('trial_searches') or 0\n",
    "    return {\n",
    "        'last_node': 'trial_search',\n",
    "        'trials': docs_retrieved,\n",
    "        'trial_searches': trial_searches + 1,\n",
    "        }\n",
    "\n",
    "def grade_trials(state: AgentState, trials: List[Document] = None):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"----- CHECKING THE TRIALS RELEVANCE TO PATIENT PROFILE ----- \")\n",
    "    \n",
    "    if trials is None:\n",
    "        trials = state['trials']\n",
    "    patient_profile = state['patient_profile']\n",
    "\n",
    "    # Score each doc\n",
    "    relevant_trials = []\n",
    "    for trial in trials:\n",
    "        doc_txt = trial.page_content\n",
    "        trial_diseases = trial.metadata['diseases']\n",
    "        nctid = trial.metadata['nctid']\n",
    "        print(f\"---GRADER: TRIAL {nctid}: ---\") \n",
    "        trial_score = retrieval_grader.invoke(\n",
    "            {\n",
    "                \"patient_profile\": patient_profile, \n",
    "                \"document\": doc_txt, \n",
    "                \"trial_diseases\": trial_diseases\n",
    "            }\n",
    "        )\n",
    "            \n",
    "        relevance_score = trial_score.relevance_score\n",
    "        if relevance_score.lower() == \"yes\":   \n",
    "            # Hullucination check         \n",
    "            explanation = trial_score.explanation            \n",
    "            factual_score = hallucination_grader.invoke({\"patient_profile\": patient_profile, \"explanation\": explanation})\n",
    "            factual_score_grade = factual_score.binary_score            \n",
    "            if factual_score_grade == \"no\":\n",
    "                print(\"--- HALLUCINATION: MODEL'S EXPLANATION IS NOT GROUNDED IN PATIENT PROFILE --> REJECTED---\")\n",
    "\n",
    "        if relevance_score.lower() == \"yes\" and factual_score_grade == \"yes\":\n",
    "            print(f\"---TRIAL RELEVANT---\")                        \n",
    "        else:\n",
    "            print(f\"--- TRIAL NOT RELEVANT---\")\n",
    "\n",
    "        trial_score_dic = dict(trial_score)\n",
    "        trial_score_dic['nctid'] = nctid            \n",
    "        relevant_trials.append(trial_score_dic)    \n",
    "        \n",
    "    return {\n",
    "        'last_node': 'grade_trials',\n",
    "        \"relevant_trials\": relevant_trials\n",
    "        }\n",
    "\n",
    "def profile_rewriter(state: AgentState):\n",
    "    patient_data = state['patient_data']\n",
    "    patient_profile_rewriten = profile_rewriter_chain.invoke({\"patient_data\": patient_data})\n",
    "    # print in capitals\n",
    "    print(\"--- PROFILE REWRITER: PATIENT'S PROFILE REWRITEN ---\")\n",
    "    # state['patient_profile'] = patient_profile_rewriten\n",
    "    return {\n",
    "        'last_node': 'profile_rewriter',\n",
    "        'patient_profile': patient_profile_rewriten\n",
    "    }\n",
    "    \n",
    "\n",
    "# ========= continue functions =========\n",
    "def should_continue_patient(state: AgentState):\n",
    "    # end = False\n",
    "    if state.get(\"patient_data\"):\n",
    "        # print('patient data found')\n",
    "        print(state.get(\"patient_profile\", 'No profile generated'))\n",
    "        return \"policy_search\"\n",
    "    else:\n",
    "        print('Patient data not found in the database')\n",
    "        return END\n",
    "        \n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        print('max revision reached')\n",
    "        # print(state.get(\"patient_data\", 1))\n",
    "        return END        \n",
    "\n",
    "def should_continue_policy(state: AgentState):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        print('max revision reached')        \n",
    "        return END\n",
    "    more_policies = len(state[\"unchecked_policies\"]) > 0\n",
    "    if state[\"policy_eligible\"]:\n",
    "        if more_policies:\n",
    "            print(\"-------------- Check the next policy --------------\")\n",
    "            return \"policy_evaluator\"\n",
    "        else:\n",
    "            print(\"-------------- Patient passed the general trials policies --------------\")\n",
    "            return \"trial_search\"\n",
    "    else:\n",
    "        print(\"Patient did not pass this policy.\\n\")\n",
    "        print(state['checked_policy'].page_content)\n",
    "        # print(\"Patient did not pass the general trials policies.\\n\")        \n",
    "        print('Rejection Reason: ')\n",
    "        nprint(state['rejection_reason'])\n",
    "        print(\"You can correct the patient's medical profile if required.\")        \n",
    "        return END\n",
    "\n",
    "def should_continue_trials(state: AgentState):\n",
    "    relevant_trials = state[\"relevant_trials\"]    \n",
    "    has_relevant_trial = any(trial['relevance_score'] == 'Yes' for trial in state[\"relevant_trials\"])\n",
    "\n",
    "    if state[\"trial_searches\"] > state[\"max_trial_searches\"]:\n",
    "        print('max trial searches reached')\n",
    "        next = END    \n",
    "    # elif not state[\"relevant_trials\"]:\n",
    "    elif has_relevant_trial == False:\n",
    "        print('----- No relevant trials found --> rewriting the patient profile -----')\n",
    "        next = \"profile_rewriter\"        \n",
    "    else:\n",
    "        next = END\n",
    "        print('to end')\n",
    "    return next\n",
    "\n",
    "\n",
    "# ==== define graph nodes====\n",
    "builder = StateGraph(AgentState)\n",
    "builder.set_entry_point(\"patient_collector\")\n",
    "builder.add_node(\"patient_collector\", patient_collector_node)\n",
    "builder.add_node(\"policy_search\", policy_search)\n",
    "builder.add_node(\"policy_evaluator\", policy_evaluator)\n",
    "builder.add_node(\"trial_search\", trial_search)\n",
    "builder.add_node(\"grade_trials\", grade_trials)\n",
    "builder.add_node(\"profile_rewriter\", profile_rewriter)\n",
    "\n",
    "# ===== define graph edges====\n",
    "builder.add_conditional_edges(\n",
    "    \"patient_collector\", \n",
    "    should_continue_patient, \n",
    "    {END: END    \n",
    "    ,\"policy_search\": \"policy_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"policy_evaluator\", \n",
    "    should_continue_policy, \n",
    "    {\n",
    "    \"trial_search\": \"trial_search\"\n",
    "    , \"policy_evaluator\": \"policy_evaluator\"\n",
    "    , END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"policy_search\", \"policy_evaluator\")\n",
    "builder.add_edge(\"trial_search\", \"grade_trials\")\n",
    "builder.add_edge(\"profile_rewriter\",\"trial_search\")\n",
    "# builder.set_finish_point(\"grade_trials\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"grade_trials\", \n",
    "    should_continue_trials, \n",
    "    {\n",
    "    \"profile_rewriter\": \"profile_rewriter\"    \n",
    "    , END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "graph = builder.compile(\n",
    "    checkpointer=memory\n",
    ")\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running with no gui and intrupts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False\n",
    "sample_patient_id = 2\n",
    "thread = {\"configurable\": {\"thread_id\": \"0\"}}\n",
    "events_gen = graph.stream({\n",
    "    'patient_prompt': f\"Is patient {sample_patient_id} eligible for any medical trial?\",    \n",
    "    \"max_revisions\": 10,\n",
    "    \"revision_number\": 1,\n",
    "    'max_trial_searches':3,\n",
    "}, thread)\n",
    "for event in events_gen:\n",
    "    print(event)\n",
    "# event = events_gen.__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_gui import trials_gui\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(\n",
    "    checkpointer=memory\n",
    "    , interrupt_after=['patient_collector', 'policy_search', 'trial_search', 'grade_trials', 'profile_rewriter']\n",
    "    # , interrupt_after=['grade_trials','profile_rewriter']\n",
    ")\n",
    "\n",
    "try:\n",
    "    app.demo.close()\n",
    "except:\n",
    "    print('initial run')\n",
    "app = trials_gui(graph)    \n",
    "app.demo.launch(server_name=\"127.0.0.1\", server_port=7959)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Further Improvements for Real Application:\n",
    "\n",
    "To enhance the robustness of the pipeline and effectively manage diverse patient and trial conditions, it is essential to implement advanced methodologies, particularly when handling large databases of patients, trials, and policies.\n",
    "\n",
    "Recommended Improvements:\n",
    "1. Graph-Based Retrieval-Augmented Generation (RAG):\n",
    "- Implement graph-based RAG to focus on the relationships between entities across different databases. For instance, map connections between patients, diseases, drugs, and trials to provide more accurate and relevant information retrieval.\n",
    "\n",
    "2. Advanced RAG pipeline:\n",
    "- The output of RAG pipelines can be improved by benefiting from more advanced techniques such as Adaptive RAG, Corrective RAG, and Self-RAG. Such pipelines are more robust againts hallucinations and wrong inferences in LLMs outputs.\n",
    "\n",
    "4. Advanced Chain of Thought Processing:\n",
    "- Employ a more sophisticated chain of thought process to cross-match the patient's profile with the detailed information provided in each trial or policy. This approach enhances the decision-making capability of the system by considering multiple factors simultaneously.\n",
    "\n",
    "1. Fine-Tuning the Large Language Model:\n",
    "- Fine-tune the large language model using a diverse set of medical trial data to improve the accuracy and relevance of its inferences. This customization ensures the model better understands the nuances and specifics of clinical trial data.\n",
    "\n",
    "1. Cyclic Graphs for Iterative Evaluation:\n",
    "- Utilize cyclic graphs to iteratively evaluate the patient's profile against various trials and policies. This iterative approach allows the system to refine its matches through multiple rounds of evaluation, ultimately identifying the best possible trial for the patient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
