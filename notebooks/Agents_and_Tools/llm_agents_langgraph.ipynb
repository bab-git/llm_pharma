{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced LLM agents with LangGraph and LangSmith\n",
    "\n",
    "In following this tutorial, you will learn how to:\n",
    "\n",
    "- Use language models, in particular their tool calling ability\n",
    "- Use a Search Tool to look up information from the Internet\n",
    "- Compose a [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/) Agent, which use an LLM to determine actions and then execute them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangSmith:**   \n",
    "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pprint\n",
    "# A function for printing nicely\n",
    "def nprint(text, indent=2):\n",
    "    pp = pprint.PrettyPrinter(indent=indent)\n",
    "    pp.pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tools\n",
    "We first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1718313877, 'localtime': '2024-06-13 14:24'}, 'current': {'last_updated_epoch': 1718313300, 'last_updated': '2024-06-13 14:15', 'temp_c': 17.8, 'temp_f': 64.0, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 12.5, 'wind_kph': 20.2, 'wind_degree': 300, 'wind_dir': 'WNW', 'pressure_mb': 1016.0, 'pressure_in': 29.99, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 63, 'cloud': 0, 'feelslike_c': 17.8, 'feelslike_f': 64.0, 'windchill_c': 15.9, 'windchill_f': 60.6, 'heatindex_c': 15.9, 'heatindex_f': 60.7, 'dewpoint_c': 9.6, 'dewpoint_f': 49.3, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 16.7, 'gust_kph': 26.9}}\"}, {'url': 'https://www.wunderground.com/hourly/us/ca/san-francisco/94134/date/2024-6-13', 'content': 'San Francisco, CA Hourly Weather Forecast. star_rate. home. Some clouds in the morning will give way to mainly sunny skies for the afternoon. High 64F. Winds SW at 10 to 20 mph. Clear skies. Low ...'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"{'location': {'name': 'San Francisco', 'region': 'California', 'country': \"\n",
      " \"'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': \"\n",
      " \"'America/Los_Angeles', 'localtime_epoch': 1718313877, 'localtime': \"\n",
      " \"'2024-06-13 14:24'}, 'current': {'last_updated_epoch': 1718313300, \"\n",
      " \"'last_updated': '2024-06-13 14:15', 'temp_c': 17.8, 'temp_f': 64.0, \"\n",
      " \"'is_day': 1, 'condition': {'text': 'Sunny', 'icon': \"\n",
      " \"'//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': \"\n",
      " \"12.5, 'wind_kph': 20.2, 'wind_degree': 300, 'wind_dir': 'WNW', \"\n",
      " \"'pressure_mb': 1016.0, 'pressure_in': 29.99, 'precip_mm': 0.0, 'precip_in': \"\n",
      " \"0.0, 'humidity': 63, 'cloud': 0, 'feelslike_c': 17.8, 'feelslike_f': 64.0, \"\n",
      " \"'windchill_c': 15.9, 'windchill_f': 60.6, 'heatindex_c': 15.9, \"\n",
      " \"'heatindex_f': 60.7, 'dewpoint_c': 9.6, 'dewpoint_f': 49.3, 'vis_km': 16.0, \"\n",
      " \"'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 16.7, 'gust_kph': 26.9}}\")\n"
     ]
    }
   ],
   "source": [
    "nprint(search_results[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Language Models\n",
    "Next, let's learn how to use a language model by to call tools. LangChain supports many different language models that you can use interchangably - select the one you want to use below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "modelID = \"gpt-3.5-turbo\"\n",
    "model = ChatOpenAI(model=modelID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the model. Let's first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the agent didn't call any tool based on the input prompt\n",
    "\n",
    "ow, let's try calling it with some input that would expect a tool to be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_ZiclSw6CK0kZvbb9k3LYTZa6'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the agent\n",
    "Now that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent. Currently we are using a high level interface to construct the agent, but the nice thing about LangGraph is that this high-level interface is backed by a low-level, highly controllable API in case you want to modify the agent logic.\n",
    "\n",
    "Now, we can initalize the agent with the LLM and the tools.\n",
    "\n",
    "Note that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', id='dc8ec231-05f5-4def-b510-24043bd8c20f'),\n",
       " AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 83, 'total_tokens': 93}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8448bac2-0168-4fa5-bb88-344c577e1893-0', usage_metadata={'input_tokens': 83, 'output_tokens': 10, 'total_tokens': 93})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in NY?', id='b7b18c7e-5e19-4053-927e-1ed469cbbf47'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_MvFLjTWS4aBLgVk4z7bQK2GZ', 'function': {'arguments': '{\"query\":\"weather in New York\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 88, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a1564e2e-ec18-422a-855c-4a94c0a2b1d7-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in New York'}, 'id': 'call_MvFLjTWS4aBLgVk4z7bQK2GZ'}], usage_metadata={'input_tokens': 88, 'output_tokens': 21, 'total_tokens': 109}),\n",
       " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'New York\\', \\'region\\': \\'New York\\', \\'country\\': \\'United States of America\\', \\'lat\\': 40.71, \\'lon\\': -74.01, \\'tz_id\\': \\'America/New_York\\', \\'localtime_epoch\\': 1718315021, \\'localtime\\': \\'2024-06-13 17:43\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718314200, \\'last_updated\\': \\'2024-06-13 17:30\\', \\'temp_c\\': 26.7, \\'temp_f\\': 80.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 162, \\'wind_dir\\': \\'SSE\\', \\'pressure_mb\\': 1016.0, \\'pressure_in\\': 29.99, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 47, \\'cloud\\': 25, \\'feelslike_c\\': 27.1, \\'feelslike_f\\': 80.7, \\'windchill_c\\': 26.8, \\'windchill_f\\': 80.3, \\'heatindex_c\\': 27.3, \\'heatindex_f\\': 81.1, \\'dewpoint_c\\': 14.8, \\'dewpoint_f\\': 58.6, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 7.0, \\'gust_mph\\': 15.9, \\'gust_kph\\': 25.6}}\"}, {\"url\": \"https://www.weathertab.com/en/c/e/06/united-states/new-york/new-york-city/\", \"content\": \"Temperature Forecast. Explore comprehensive June 2024 weather forecasts for New York City, including daily high and low temperatures, precipitation risks, and monthly temperature trends. Featuring detailed day-by-day forecasts, dynamic graphs of daily rain probabilities, and temperature trends to help you plan ahead.\"}]', name='tavily_search_results_json', id='7933fa5b-8c44-4295-8ada-47c06bca6c86', tool_call_id='call_MvFLjTWS4aBLgVk4z7bQK2GZ'),\n",
       " AIMessage(content='The current weather in New York is partly cloudy with a temperature of 80.1°F (26.7°C). The wind is coming from the SSE direction at 3.6 km/h. The humidity is at 47%, and the visibility is 9.0 miles.', response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 616, 'total_tokens': 674}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6f8acfdb-c7f0-4c8d-844e-90df5457b48b-0', usage_metadata={'input_tokens': 616, 'output_tokens': 58, 'total_tokens': 674})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in NY?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming intermediate Messages\n",
    "We've seen how the agent can be called with .invoke to get back a final response. If the agent is executing multiple steps, that may take a while. In order to show intermediate progress, we can stream back messages as they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xmOWOBt5cZskvtR6cgCugGvi', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 88, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-89f10d09-3835-4d31-9b65-ad00fdc2580a-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_xmOWOBt5cZskvtR6cgCugGvi'}], usage_metadata={'input_tokens': 88, 'output_tokens': 21, 'total_tokens': 109})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1718315225, \\'localtime\\': \\'2024-06-13 14:47\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718315100, \\'last_updated\\': \\'2024-06-13 14:45\\', \\'temp_c\\': 17.8, \\'temp_f\\': 64.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 12.5, \\'wind_kph\\': 20.2, \\'wind_degree\\': 300, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1016.0, \\'pressure_in\\': 29.99, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 63, \\'cloud\\': 0, \\'feelslike_c\\': 17.8, \\'feelslike_f\\': 64.0, \\'windchill_c\\': 15.9, \\'windchill_f\\': 60.6, \\'heatindex_c\\': 15.9, \\'heatindex_f\\': 60.7, \\'dewpoint_c\\': 9.6, \\'dewpoint_f\\': 49.3, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 16.7, \\'gust_kph\\': 26.9}}\"}, {\"url\": \"https://www.wunderground.com/weather/us/ca/san-francisco\", \"content\": \"San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area. ... 2024 (GMT -7 ...\"}]', name='tavily_search_results_json', tool_call_id='call_xmOWOBt5cZskvtR6cgCugGvi')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='The current weather in San Francisco is sunny with a temperature of 64.0°F (17.8°C). The wind speed is 20.2 km/h coming from the WNW direction. The humidity is at 63%, and there is no precipitation at the moment.', response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 594, 'total_tokens': 651}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-77a76667-7554-4657-88e4-5df918308c17-0', usage_metadata={'input_tokens': 594, 'output_tokens': 57, 'total_tokens': 651})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in memory\n",
    "As mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Hello Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 85, 'total_tokens': 96}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3cd05824-a0dd-46c0-b19f-be2e5c8c6cd2-0', usage_metadata={'input_tokens': 85, 'output_tokens': 11, 'total_tokens': 96})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob! How can I help you further, Bob?', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 108, 'total_tokens': 123}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4885ff68-9d17-422f-b88d-7f67d27a52ac-0', usage_metadata={'input_tokens': 108, 'output_tokens': 15, 'total_tokens': 123})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to start a new conversation, all I have to do is change the thread_id used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"I don't have access to personal information like your name. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 86, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bac537f2-33de-4e38-b38c-fe548be9fe8a-0', usage_metadata={'input_tokens': 86, 'output_tokens': 20, 'total_tokens': 106})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
