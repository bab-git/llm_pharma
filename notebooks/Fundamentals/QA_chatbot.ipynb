{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Basics of Chatbots and Conversational Agents\n",
    "\n",
    "In this notebook, we work on the following topics:\n",
    "- A direct API call from OpenAI to perform chat completions\n",
    "- Chat completions with Langchain APIs\n",
    "- Using prompt template to create custom prompt\n",
    "- Using output parser to extract key information from the completion\n",
    "\n",
    "**Use cases:**\n",
    "- Technical support as a chatbot technician.\n",
    "- Entity extraction from cusomer travel query.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "module_dir = os.path.abspath('../../src')  # Gets the absolute path to the src directory\n",
    "sys.path.append(module_dir)\n",
    "from helper_functions import llm_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for printing nicely\n",
    "def nprint(text, indent=2):\n",
    "    pp = pprint.PrettyPrinter(indent=indent)\n",
    "    pp.pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelID = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical support as a chatbot technician.\n",
    "Here the LLM chatbot gives technical support to the customer to fix it's problem.  \n",
    "We use system context as well as answering styles to customize the chatbot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('If your screen freezes, you can try the following steps to resolve the '\n",
      " 'issue:\\n'\n",
      " '\\n'\n",
      " '1. Wait for a few moments: Sometimes the screen may freeze temporarily, so '\n",
      " 'give it a few seconds to see if it resolves on its own.\\n'\n",
      " '\\n'\n",
      " \"2. Restart your device: If waiting doesn't work, try restarting your device. \"\n",
      " 'This can help refresh the system and resolve any temporary glitches causing '\n",
      " 'the freeze.\\n'\n",
      " '\\n'\n",
      " \"3. Check for software updates: Make sure your device's operating system and \"\n",
      " 'apps are up to date. Sometimes freezes can occur due to outdated software.\\n'\n",
      " '\\n'\n",
      " '4. Close any unresponsive apps: If a specific app is causing the freeze, try '\n",
      " 'closing it by using the task manager or force quitting the app.\\n'\n",
      " '\\n'\n",
      " '5. Remove any peripherals: If you have any external devices connected to '\n",
      " 'your device, such as a USB drive or external monitor, try disconnecting them '\n",
      " 'to see if they are causing the issue.\\n'\n",
      " '\\n'\n",
      " '6. Perform a hard reset: If the screen remains frozen and none of the above '\n",
      " 'steps work, you may need to perform a hard reset on your device. This '\n",
      " 'involves holding down the power button for a few seconds until the device '\n",
      " 'powers off, and then turning it back on.\\n'\n",
      " '\\n'\n",
      " 'If the issue persists after trying these steps, you may need to seek further '\n",
      " 'assistance from the manufacturer or a technical support professional.')\n"
     ]
    }
   ],
   "source": [
    "question = \"What do I do if my screen freezes?\"\n",
    "completion = llm_completion(question, model=modelID)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the completion Style and System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1. Try pressing Ctrl + Alt + Delete on Windows or Command + Option + Escape '\n",
      " 'on Mac to open the Task Manager or Force Quit window.\\n'\n",
      " \"2. If that doesn't work, try restarting your computer by holding down the \"\n",
      " 'power button until it shuts off, then turning it back on.\\n'\n",
      " '3. If the issue persists, check for any software updates or run a virus scan '\n",
      " 'to rule out any potential software issues.\\n'\n",
      " '4. If the problem continues, consider seeking help from a professional '\n",
      " 'technician to diagnose and fix the underlying cause of the freeze.')\n"
     ]
    }
   ],
   "source": [
    "sys_content = \"You are an expert technician who gives exact, clear, and short steps to solving a problem.\"\n",
    "completion = llm_completion(question, model=modelID, sys_content=sys_content)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets change the style of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do I do if my screen freezes? \n",
      "The answer must be understabdable for a 5 year old child.\n",
      "\n",
      "('1. Press and hold the power button on your device.\\n'\n",
      " '2. Wait for a few seconds until the screen turns off.\\n'\n",
      " '3. Turn on your device again by pressing the power button once.')\n"
     ]
    }
   ],
   "source": [
    "style = \"The answer must be understabdable for a 5 year old child.\"\n",
    "prompt = f\"\"\"{question} \n",
    "{style}\n",
    "\"\"\"\n",
    "print(prompt)\n",
    "\n",
    "completion = llm_completion(prompt, model=modelID, sys_content=sys_content)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it even more simpler for the child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('If your screen freezes, just give it a little tickle by pressing the restart '\n",
      " \"button or asking a grown-up to help you turn it off and on again. It's like \"\n",
      " 'giving your screen a little nap to wake it up feeling refreshed!')\n"
     ]
    }
   ],
   "source": [
    "sys_content = \"You are a cool 5 years old child with funny sense of humor.\"\n",
    "\n",
    "completion = llm_completion(prompt, model=modelID, sys_content=sys_content)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it even more creative by increasing the tempreature of the LLM model to 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = llm_completion(prompt, model=modelID, sys_content=sys_content, temperature=2.0)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Langchain APIs to perform chat completions\n",
    "Now we perform the above chat completions using Langchain modules which are more simpler and easier to use.  \n",
    "We use prompt template to create the prompt with different style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{sys_content}\u001b[0m\n",
      "Answer the following question:  \n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Style: \u001b[33;1m\u001b[1;3m{style}\u001b[0m\n",
      "\n",
      "['question', 'style', 'sys_content']\n"
     ]
    }
   ],
   "source": [
    "QAchat = ChatOpenAI(temperature=0, model=modelID)\n",
    "template = \"\"\"{sys_content}\n",
    "Answer the following question:  \n",
    "{question} \n",
    "Style: {style}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "prompt_template.pretty_print()\n",
    "print(prompt_template.messages[0].prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='You are a cool 5 years old child with funny sense of humor.\\nAnswer this following question:  \\nWhat do I do if my screen freezes? \\nStyle: The answer must be understabdable for a 5 year old child.\\n')]\n",
      "The formated prompt is:\n",
      "\n",
      "('You are a cool 5 years old child with funny sense of humor.\\n'\n",
      " 'Answer this following question:  \\n'\n",
      " 'What do I do if my screen freezes? \\n'\n",
      " 'Style: The answer must be understabdable for a 5 year old child.\\n')\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format_messages(\n",
    "                    sys_content = sys_content,\n",
    "                    style=style,\n",
    "                    question=question)\n",
    "print(prompt)\n",
    "print(\"The formated prompt is:\\n\")\n",
    "nprint(prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('If your screen freezes, you can try turning it off and then back on again. '\n",
      " 'Just like when you need a nap to feel better, sometimes your screen needs a '\n",
      " 'little rest too!')\n"
     ]
    }
   ],
   "source": [
    "completion = QAchat(prompt)\n",
    "nprint(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using output parser\n",
    "Here we use output parser to extract key information from the completion.  \n",
    "We need this information to be extracted as a JSON object, so we can use it as a dictionary.\n",
    "So, We define a custom format instructions to let LLM know what information must be extracted from the completion.\n",
    "\n",
    "**Use case**: Travel and Hospitality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample query from the user from which we extract the key information about the trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_query = \"\"\"\\\n",
    "We're planning a family vacation to Hawaii in December. \\\n",
    "We need recommendations for family-friendly hotels and activities suitable for kids. \\\n",
    "Also, any travel advisories we should be aware of?\\\n",
    "Our budget for the entire trip is around $5000.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ResponseSchema to define how the key information must be extracted from the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"destination\": string  // What is the destination of the trip?\n",
      "\t\"travel_date\": string  // When is the trip planned for?\n",
      "\t\"requests\": string  // Extract any specific requests made by the traveler,\n",
      "                                    and output them as a comma separated Python list.\n",
      "\t\"budget\": string  // What is the budget for the entire trip? \n",
      "                                If this information is not found, output -1.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "destination_schema = ResponseSchema(name=\"destination\",\n",
    "                             description=\"What is the destination of the trip?\")\n",
    "travel_date_schema = ResponseSchema(name=\"travel_date\",\n",
    "                                      description=\"When is the trip planned for?\")\n",
    "requests_schema = ResponseSchema(name=\"requests\",\n",
    "                                    description=\"\"\"Extract any specific requests made by the traveler,\n",
    "                                    and output them as a comma separated Python list.\"\"\")\n",
    "budget_schema = ResponseSchema(name=\"budget\",\n",
    "                             description=\"\"\"What is the budget for the entire trip? \n",
    "                                If this information is not found, output -1.\"\"\")\n",
    "\n",
    "completion_schemas = [destination_schema, \n",
    "                    travel_date_schema,\n",
    "                    requests_schema,\n",
    "                    budget_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(completion_schemas)        \n",
    "# output_parser\n",
    "format_instructions = output_parser.get_format_instructions()            \n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "For the following query, extract the following information:\n",
      "\n",
      "destination: What is the destination of the trip?\n",
      "travel_date: When is the trip planned for?\n",
      "requests: Extract any specific requests made by the traveler,and output them as a comma separated Python list.\n",
      "\n",
      "budget: What is the budget for the entire trip? If this information is not found, output -1.\n",
      "\n",
      "Format the output as JSON with the following keys:\n",
      "destination\n",
      "travel_date\n",
      "requests\n",
      "budget\n",
      "\n",
      "query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{format_instructions}\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vacation_template = \"\"\"\\\n",
    "For the following query, extract the following information:\n",
    "\n",
    "destination: What is the destination of the trip?\\\n",
    "\n",
    "travel_date: When is the trip planned for?\\\n",
    "\n",
    "requests: Extract any specific requests made by the traveler,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "budget: What is the budget for the entire trip? \\\n",
    "If this information is not found, output -1.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "destination\n",
    "travel_date\n",
    "requests\n",
    "budget\n",
    "\n",
    "query: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(vacation_template)\n",
    "prompt_template.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='For the following query, extract the following information:\\n\\ndestination: What is the destination of the trip?\\ntravel_date: When is the trip planned for?\\nrequests: Extract any specific requests made by the traveler,and output them as a comma separated Python list.\\n\\nbudget: What is the budget for the entire trip? If this information is not found, output -1.\\n\\nFormat the output as JSON with the following keys:\\ndestination\\ntravel_date\\nrequests\\nbudget\\n\\nquery: We\\'re planning a family vacation to Hawaii in December. We need recommendations for family-friendly hotels and activities suitable for kids. Also, any travel advisories we should be aware of?Our budget for the entire trip is around $5000.\\n\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"destination\": string  // What is the destination of the trip?\\n\\t\"travel_date\": string  // When is the trip planned for?\\n\\t\"requests\": string  // Extract any specific requests made by the traveler,\\n                                    and output them as a comma separated Python list.\\n\\t\"budget\": string  // What is the budget for the entire trip? \\n                                If this information is not found, output -1.\\n}\\n```\\n')]\n",
      "The formated prompt is:\n",
      "\n",
      "('For the following query, extract the following information:\\n'\n",
      " '\\n'\n",
      " 'destination: What is the destination of the trip?\\n'\n",
      " 'travel_date: When is the trip planned for?\\n'\n",
      " 'requests: Extract any specific requests made by the traveler,and output them '\n",
      " 'as a comma separated Python list.\\n'\n",
      " '\\n'\n",
      " 'budget: What is the budget for the entire trip? If this information is not '\n",
      " 'found, output -1.\\n'\n",
      " '\\n'\n",
      " 'Format the output as JSON with the following keys:\\n'\n",
      " 'destination\\n'\n",
      " 'travel_date\\n'\n",
      " 'requests\\n'\n",
      " 'budget\\n'\n",
      " '\\n'\n",
      " \"query: We're planning a family vacation to Hawaii in December. We need \"\n",
      " 'recommendations for family-friendly hotels and activities suitable for kids. '\n",
      " 'Also, any travel advisories we should be aware of?Our budget for the entire '\n",
      " 'trip is around $5000.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'The output should be a markdown code snippet formatted in the following '\n",
      " 'schema, including the leading and trailing \"```json\" and \"```\":\\n'\n",
      " '\\n'\n",
      " '```json\\n'\n",
      " '{\\n'\n",
      " '\\t\"destination\": string  // What is the destination of the trip?\\n'\n",
      " '\\t\"travel_date\": string  // When is the trip planned for?\\n'\n",
      " '\\t\"requests\": string  // Extract any specific requests made by the '\n",
      " 'traveler,\\n'\n",
      " '                                    and output them as a comma separated '\n",
      " 'Python list.\\n'\n",
      " '\\t\"budget\": string  // What is the budget for the entire trip? \\n'\n",
      " '                                If this information is not found, output '\n",
      " '-1.\\n'\n",
      " '}\\n'\n",
      " '```\\n')\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format_messages(\n",
    "    query = customer_query,\n",
    "    format_instructions = format_instructions)\n",
    "print(prompt)\n",
    "print(\"The formated prompt is:\\n\")\n",
    "nprint(prompt[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"destination\": \"Hawaii\",\n",
      "\t\"travel_date\": \"December\",\n",
      "\t\"requests\": \"family-friendly hotels, activities suitable for kids, travel advisories\",\n",
      "\t\"budget\": \"$5000\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "completion = QAchat(prompt)\n",
    "print(completion.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
