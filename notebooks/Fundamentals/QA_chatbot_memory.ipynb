{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using memory to have an Interactive Conversational Chatbot\n",
    "\n",
    "In this notebook, we use Langchain to add memory to the LLM chatbot.  \n",
    "The memory helps the LLM to keep track of the conversation and answer based on the context.  \n",
    "\n",
    "**Case studies:** \n",
    "- Technical support\n",
    "- Customer support\n",
    "- Healthcare consultation\n",
    "\n",
    "We are going to covers the following:\n",
    "- Complete memory recording\n",
    "- Window based memory\n",
    "- Summary based memory\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for printing nicely\n",
    "def nprint(text, indent=2):\n",
    "    pp = pprint.PrettyPrinter(indent=indent)\n",
    "    pp.pprint(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelID = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical support as a chatbot technician\n",
    "Here the LLM chatbot gives technical support to the customer to fix it's problem.  \n",
    "We use system context to customize the chatbot response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the chatbot model and system role\n",
    "from langchain_openai import ChatOpenAI\n",
    "sys_content = \"\"\"\n",
    "You are an expert technician who gives exact, clear, and short steps to solving a problem.\\\n",
    "Give the instruction in seperate steps.\n",
    "\"\"\"\n",
    "QAchat = ChatOpenAI(temperature=0, model=modelID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple question to get some intstruction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1. Press and hold the power button on your device until it shuts down.\\n'\n",
      " '2. Wait a few seconds, then press the power button again to turn it back '\n",
      " 'on.\\n'\n",
      " '3. If the screen continues to freeze, try restarting the device in safe mode '\n",
      " \"(refer to your device's manual for instructions).\\n\"\n",
      " '4. If the issue persists, consider performing a factory reset or seeking '\n",
      " 'help from a professional technician.')\n"
     ]
    }
   ],
   "source": [
    "question = \"What do I do if my screen freezes?\"\n",
    "prompt = [\n",
    "    (\n",
    "        \"system\",\n",
    "        f'{sys_content}',\n",
    "    ),\n",
    "    (\"human\", f'{question}'),\n",
    "]\n",
    "prompt\n",
    "completion = QAchat.invoke(prompt)\n",
    "nprint(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using no memory\n",
    "Let's see if LLM can remember the steps by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sure! The second step typically involves analyzing the data that was '\n",
      " 'collected in the first step. This may include organizing the data, '\n",
      " 'identifying patterns or trends, and drawing conclusions based on the data. '\n",
      " 'It may also involve comparing the data to previous research or industry '\n",
      " 'standards to see how it aligns or differs. This step is crucial in gaining '\n",
      " 'insights and understanding the implications of the data collected. It helps '\n",
      " 'to inform decision-making and can guide future actions or strategies.')\n"
     ]
    }
   ],
   "source": [
    "completion = QAchat.invoke(\"Please explain the 2nd step in more detail\")\n",
    "nprint(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using memory: Complete chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Defining the buffer memory for the chatbot\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=QAchat, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: \n",
      "You are an expert technician who gives exact, clear, and short steps to solving a problem.Give the instruction in seperate steps.\n",
      "\n",
      "Answer the following question:  \n",
      "What do I do if my screen freezes? \n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('Sure! Here are the steps to follow if your screen freezes:\\n'\n",
      " '\\n'\n",
      " 'Step 1: Try pressing Ctrl + Alt + Delete on your keyboard to bring up the '\n",
      " 'Task Manager.\\n'\n",
      " 'Step 2: In the Task Manager, look for any unresponsive programs or '\n",
      " 'processes.\\n'\n",
      " 'Step 3: Select the frozen program or process and click on \"End Task\" to '\n",
      " 'force it to close.\\n'\n",
      " 'Step 4: If the screen is still frozen, try restarting your computer by '\n",
      " 'holding down the power button until it shuts off.\\n'\n",
      " 'Step 5: Once the computer has restarted, check if the issue is resolved. If '\n",
      " 'not, you may need to seek further assistance from a technician.')\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"{sys_content}\n",
    "Answer the following question:  \n",
    "{question} \n",
    "\"\"\"\n",
    "completion = conversation.predict(input=prompt)\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it can remember the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: \n",
      "You are an expert technician who gives exact, clear, and short steps to solving a problem.Give the instruction in seperate steps.\n",
      "\n",
      "Answer the following question:  \n",
      "What do I do if my screen freezes? \n",
      "\n",
      "AI: Sure! Here are the steps to follow if your screen freezes:\n",
      "\n",
      "Step 1: Try pressing Ctrl + Alt + Delete on your keyboard to bring up the Task Manager.\n",
      "Step 2: In the Task Manager, look for any unresponsive programs or processes.\n",
      "Step 3: Select the frozen program or process and click on \"End Task\" to force it to close.\n",
      "Step 4: If the screen is still frozen, try restarting your computer by holding down the power button until it shuts off.\n",
      "Step 5: Once the computer has restarted, check if the issue is resolved. If not, you may need to seek further assistance from a technician.\n",
      "Human: Explain the step 2 in more detail\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "('In step 2, when you open the Task Manager, you will see a list of all the '\n",
      " 'programs and processes currently running on your computer. Look for any '\n",
      " 'programs or processes that are marked as \"Not Responding\" or are using a lot '\n",
      " 'of system resources. These are likely the ones causing the screen to freeze. '\n",
      " 'Select the program or process by clicking on it, and then click on the \"End '\n",
      " 'Task\" button to force it to close. This should help unfreeze your screen.')\n"
     ]
    }
   ],
   "source": [
    "completion = conversation.predict(input=\"Explain the step 2 in more detail\")\n",
    "nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a question from the first answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: \n",
      "You are an expert technician who gives exact, clear, and short steps to solving a problem.Give the instruction in seperate steps.\n",
      "\n",
      "Answer the following question:  \n",
      "What do I do if my screen freezes? \n",
      "\n",
      "AI: Sure! Here are the steps to follow if your screen freezes:\n",
      "\n",
      "Step 1: Try pressing Ctrl + Alt + Delete on your keyboard to bring up the Task Manager.\n",
      "Step 2: In the Task Manager, look for any unresponsive programs or processes.\n",
      "Step 3: Select the frozen program or process and click on \"End Task\" to force it to close.\n",
      "Step 4: If the screen is still frozen, try restarting your computer by holding down the power button until it shuts off.\n",
      "Step 5: Once the computer has restarted, check if the issue is resolved. If not, you may need to seek further assistance from a technician.\n",
      "Human: Explain the step 2 in more detail\n",
      "AI: In step 2, when you open the Task Manager, you will see a list of all the programs and processes currently running on your computer. Look for any programs or processes that are marked as \"Not Responding\" or are using a lot of system resources. These are likely the ones causing the screen to freeze. Select the program or process by clicking on it, and then click on the \"End Task\" button to force it to close. This should help unfreeze your screen.\n",
      "Human: Explain the step 3 in more detail\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "completion = conversation.predict(input=\"Explain the step 3 in more detail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In step 3, after selecting the frozen program or process in the Task '\n",
      " 'Manager, you will see an \"End Task\" button at the bottom right corner of the '\n",
      " 'window. Click on this button to force the program or process to close. This '\n",
      " 'action will stop the unresponsive program from running and potentially '\n",
      " \"causing your screen to freeze. It's important to only end tasks for programs \"\n",
      " 'or processes that are not responding, as ending tasks for essential system '\n",
      " 'processes can cause issues with your computer.')\n",
      "\n",
      " Length of buffer: 1822\n"
     ]
    }
   ],
   "source": [
    "nprint(completion)\n",
    "print(f'\\n Length of buffer: {len(memory.buffer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the complete memory content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Human: \\n'\n",
      " 'You are an expert technician who gives exact, clear, and short steps to '\n",
      " 'solving a problem.Give the instruction in seperate steps.\\n'\n",
      " '\\n'\n",
      " 'Answer the following question:  \\n'\n",
      " 'What do I do if my screen freezes? \\n'\n",
      " '\\n'\n",
      " 'AI: Sure! Here are the steps to follow if your screen freezes:\\n'\n",
      " '\\n'\n",
      " 'Step 1: Try pressing Ctrl + Alt + Delete on your keyboard to bring up the '\n",
      " 'Task Manager.\\n'\n",
      " 'Step 2: In the Task Manager, look for any unresponsive programs or '\n",
      " 'processes.\\n'\n",
      " 'Step 3: Select the frozen program or process and click on \"End Task\" to '\n",
      " 'force it to close.\\n'\n",
      " 'Step 4: If the screen is still frozen, try restarting your computer by '\n",
      " 'holding down the power button until it shuts off.\\n'\n",
      " 'Step 5: Once the computer has restarted, check if the issue is resolved. If '\n",
      " 'not, you may need to seek further assistance from a technician.\\n'\n",
      " 'Human: Explain the step 2 in more detail\\n'\n",
      " 'AI: In step 2, when you open the Task Manager, you will see a list of all '\n",
      " 'the programs and processes currently running on your computer. Look for any '\n",
      " 'programs or processes that are marked as \"Not Responding\" or are using a lot '\n",
      " 'of system resources. These are likely the ones causing the screen to freeze. '\n",
      " 'Select the program or process by clicking on it, and then click on the \"End '\n",
      " 'Task\" button to force it to close. This should help unfreeze your screen.\\n'\n",
      " 'Human: Explain the step 3 in more detail\\n'\n",
      " 'AI: In step 3, after selecting the frozen program or process in the Task '\n",
      " 'Manager, you will see an \"End Task\" button at the bottom right corner of the '\n",
      " 'window. Click on this button to force the program or process to close. This '\n",
      " 'action will stop the unresponsive program from running and potentially '\n",
      " \"causing your screen to freeze. It's important to only end tasks for programs \"\n",
      " 'or processes that are not responding, as ending tasks for essential system '\n",
      " 'processes can cause issues with your computer.')\n"
     ]
    }
   ],
   "source": [
    "nprint(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using memory: Partial chat history\n",
    "\n",
    "Here, the memory module only holds the last few exchanges of the whole conversation.  \n",
    "We also construct the LLM to ask for any missing or information that is beyond its memory window.   \n",
    "**Use case:** Customer support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Human: It's 123456.\\n\"\n",
      " 'AI: Thank you. What seems to be the problem with your order?\\n'\n",
      " 'Human: The item I received is damaged.\\n'\n",
      " \"AI: I'm sorry for the inconvenience. Would you like a replacement or a \"\n",
      " 'refund?')\n"
     ]
    }
   ],
   "source": [
    "#  Setting up the memory and loading it with sample conversation history\n",
    "\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "conversation_flow = [\n",
    "    {\"input\": \"Hi, I'm having an issue with my recent order.\", \"output\": \"I'm sorry to hear that. Can you please provide your order number?\"},\n",
    "    {\"input\": \"It's 123456.\", \"output\": \"Thank you. What seems to be the problem with your order?\"},\n",
    "    {\"input\": \"The item I received is damaged.\", \"output\": \"I'm sorry for the inconvenience. Would you like a replacement or a refund?\"},\n",
    "    # {\"input\": \"I'd prefer a replacement.\", \"output\": \"I'll arrange for a replacement. Can you confirm your shipping address is the same as on the order?\"},\n",
    "    # {\"input\": \"Yes, the shipping address is the same.\", \"output\": \"Great, I've processed the replacement order for you. You'll receive an email confirmation shortly. Could you please send a photo of the damaged item to our support email for our records?\"},\n",
    "    # {\"input\": \"Sure, I can do that. What is the support email?\", \"output\": \"The support email is support@example.com. Once we receive the photo, we can expedite the replacement process. Is there anything specific you'd like us to check in the replacement item?\"},\n",
    "    # {\"input\": \"Yes, please make sure it's properly packaged this time.\", \"output\": \"Absolutely, we'll ensure it's securely packaged. Do you need any assistance with returning the damaged item?\"}\n",
    "]\n",
    "\n",
    "# Adding the conversation flow to the buffer\n",
    "for conversation in conversation_flow:\n",
    "    memory.save_context({'input':conversation[\"input\"]},{'output': conversation[\"output\"]})\n",
    "\n",
    "# Looking at the memory buffer\n",
    "nprint(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the LLM assistant agent and its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "The following is a conversation between a human and an AI. \\\n",
    "The AI is a customer service agent who helps the customer to solve problems with their recent orders.\\\n",
    "The AI asks information from the customer where required. \\\n",
    "To send a replacement, AI needs to confirm if the shipping address is the same on the order. \\\n",
    "To process damaged items the AI needs a photo of the damaged item. \\\n",
    "Only ask one question at a time. \\\n",
    "The AI suggestions is in the framework of an ecommerce store and follows the standard conversation protocols of customer supports in such environments. \n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=QAchat,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now proceeding with the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Thank you for letting us know. Could you please provide a photo of the '\n",
      " 'damaged item so we can process the replacement?')\n",
      "\n",
      " THE MEMORY BUFFER: \n",
      "\n",
      "('Human: The item I received is damaged.\\n'\n",
      " \"AI: I'm sorry for the inconvenience. Would you like a replacement or a \"\n",
      " 'refund?\\n'\n",
      " \"Human: I'd prefer a replacement.\\n\"\n",
      " 'AI: Thank you for letting us know. Could you please provide a photo of the '\n",
      " 'damaged item so we can process the replacement?')\n"
     ]
    }
   ],
   "source": [
    "completion = conversation.predict(input=\"I'd prefer a replacement.\")\n",
    "nprint(completion)\n",
    "print('\\n THE MEMORY BUFFER: \\n')\n",
    "nprint(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Thank you for sending the photo. Just to confirm, is the shipping address on '\n",
      " 'your order still the same for the replacement item to be sent to?')\n",
      "\n",
      " THE MEMORY BUFFER: \n",
      "\n",
      "(\"Human: I'd prefer a replacement.\\n\"\n",
      " 'AI: Thank you for letting us know. Could you please provide a photo of the '\n",
      " 'damaged item so we can process the replacement?\\n'\n",
      " 'Human: I sent it to the support email.\\n'\n",
      " 'AI: Thank you for sending the photo. Just to confirm, is the shipping '\n",
      " 'address on your order still the same for the replacement item to be sent to?')\n"
     ]
    }
   ],
   "source": [
    "completion = conversation.predict(input=\"I sent it to the support email.\")\n",
    "nprint(completion)\n",
    "print('\\n THE MEMORY BUFFER: \\n')\n",
    "nprint(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Great, thank you for confirming. We will process the replacement order for '\n",
      " 'you. Is there anything else I can assist you with today?')\n",
      "\n",
      " THE MEMORY BUFFER: \n",
      "\n",
      "('Human: I sent it to the support email.\\n'\n",
      " 'AI: Thank you for sending the photo. Just to confirm, is the shipping '\n",
      " 'address on your order still the same for the replacement item to be sent '\n",
      " 'to?\\n'\n",
      " \"Human: Yes, It's the same address.\\n\"\n",
      " 'AI: Great, thank you for confirming. We will process the replacement order '\n",
      " 'for you. Is there anything else I can assist you with today?')\n"
     ]
    }
   ],
   "source": [
    "completion = conversation.predict(input=\"Yes, It's the same address.\")\n",
    "nprint(completion)\n",
    "print('\\n THE MEMORY BUFFER: \\n')\n",
    "nprint(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using memory: Summary of chat history\n",
    "\n",
    "Here the memory module hold the summary of the chat history so far.   \n",
    "**Use Case:** Healthcare - summarizing patient consultations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(llm=QAchat, max_token_limit=100)\n",
    "\n",
    "# A sample conversation flow than can happen as a patient consultation\n",
    "conversation_flow = [\n",
    "    {\"input\": \"I've been experiencing severe headaches for the past two weeks.\", \"output\": \"Can you describe the type of headache? Is it throbbing, constant, or does it come and go?\"},\n",
    "    {\"input\": \"It's a constant dull ache that sometimes becomes throbbing.\", \"output\": \"Are there any other symptoms accompanying the headache, like nausea or sensitivity to light?\"},\n",
    "    {\"input\": \"Yes, I often feel nauseous and I'm very sensitive to bright lights.\", \"output\": \"Have you taken any medication for these headaches?\"},\n",
    "    {\"input\": \"I've been taking over-the-counter pain relievers, but they don't seem to help much.\", \"output\": \"Do you have a history of migraines or any other medical conditions?\"},\n",
    "    {\"input\": \"I had migraines as a teenager, but they went away for a while. I also have high blood pressure.\", \"output\": \"Understood. I'll summarize this conversation for the doctor. Is there anything else you'd like to add?\"},\n",
    "    {\"input\": \"No, that's all for now. Thank you.\", \"output\": \"\"}\n",
    "]\n",
    "\n",
    "# Adding the conversation flow to the buffer\n",
    "for conversation in conversation_flow:\n",
    "    memory.save_context({'input':conversation[\"input\"]},{'output': conversation[\"output\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at how llm summarized the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('System: The human mentions experiencing severe headaches for the past two '\n",
      " 'weeks, describing them as a constant dull ache that sometimes becomes '\n",
      " 'throbbing. The AI asks about accompanying symptoms like nausea and '\n",
      " 'sensitivity to light, to which the human confirms. The AI inquires about '\n",
      " 'medication for the headaches, and the human responds that over-the-counter '\n",
      " \"pain relievers haven't been effective.\\n\"\n",
      " 'AI: Do you have a history of migraines or any other medical conditions?\\n'\n",
      " 'Human: I had migraines as a teenager, but they went away for a while. I also '\n",
      " 'have high blood pressure.\\n'\n",
      " \"AI: Understood. I'll summarize this conversation for the doctor. Is there \"\n",
      " \"anything else you'd like to add?\\n\"\n",
      " \"Human: No, that's all for now. Thank you.\\n\"\n",
      " 'AI: ')\n"
     ]
    }
   ],
   "source": [
    "nprint(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now asking specific questions about the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Question: What are the patient's main symptoms?\\n\"\n",
      "(\"The patient's main symptoms include severe headaches that have been constant \"\n",
      " 'for the past two weeks, described as a dull ache that sometimes becomes '\n",
      " 'throbbing. The patient also experiences nausea and sensitivity to light. '\n",
      " 'Additionally, the patient has a history of migraines as a teenager and '\n",
      " 'currently has high blood pressure.')\n",
      "'Question: What medications has the patient taken?\\n'\n",
      "('The patient has taken over-the-counter pain relievers for the headaches, but '\n",
      " 'they have not been effective.')\n",
      "'Question: Does the patient have any relevant medical history?\\n'\n",
      "('The patient had migraines as a teenager but they went away for a while. The '\n",
      " 'patient also has high blood pressure.')\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=QAchat, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n",
    "questions = [\n",
    "    \"What are the patient's main symptoms?\",\n",
    "    \"What medications has the patient taken?\",\n",
    "    \"Does the patient have any relevant medical history?\"\n",
    "]\n",
    "for question in questions:\n",
    "    nprint(f\"Question: {question}\\n\")\n",
    "    completion = conversation.predict(input=question)\n",
    "    nprint(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We saw that it is possible to use Langchain's memory module to keep track of the conversation. However, keeping all history in the memory can incur unnecessary load on the LLM.  \n",
    "Based on the task and context, one can use the window based buffer memeory or summary based memory.  \n",
    "Keep in mind that summary based memory can also cost additional costs on the LLM application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
